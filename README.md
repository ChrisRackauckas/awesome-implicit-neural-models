# awesome-implicit-neural-models
A collection of resources on *Implicit* learning model, ranging from Neural ODEs to Equilibrium Networks, Differentiable Optimization Layers and more.

**NOTE:** Feel free to suggest additions via `Issues` or `Pull Requests`.

# Table of Contents

* **Implicit Deep Learning**

	* [Neural ODEs](#neural-odes)
	
	* [Deep Equilibrium Networks](#deep-equilibrium-networks)
	
	* [Optimization Layers](#optimization-layers)

	
* **Additional Material**
  * [Software and Libraries](#software-and-libraries)

  * [Websites and Blogs](#websites-and-blogs)

## Implicit Deep Learning

### Neural ODEs

* Neural Ordinary Differential Equations (best paper award): [NeurIPS18](https://arxiv.org/pdf/1806.07366.pdf)

> We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions

* Dissecting Neural ODEs (oral): [NeurIPS20](https://arxiv.org/abs/2002.08071)

> In this work, we “open the box” and offer a system–theoretic perspective with the aim of clarifying the influence of several design choices on the underlying dynamics. We formulate and solve the infinite–dimensional problem linked to the true deep limit formulation of Neural ODE. We provide numerical approximations to the infinite–dimensional problem, leading to novel model variants, such as Galerkin and piecewise–constant Neural ODEs. Augmentation is developed beyond existing approaches to include input–layer and higher–order augmentation strategies. Finally, the novel paradigms of data–control (vector field conditioning) and depth–adaptation are introduced.

* Augmented Neural ODEs: [NeurIPS19](https://arxiv.org/abs/1904.01681)


### Deep Equilibrium Networks

* Deep Equilibrium Models: [NeurIPS19](https://arxiv.org/abs/1909.01377)

> We present a new approach to modeling sequential data: the deep equilibrium model (DEQ). Motivated by an observation that the hidden layers of many existing deep sequence models converge towards some fixed point, we propose the DEQ approach that directly finds these equilibrium points via root-finding.

### Optimization Layers



## Additional Material

### Software and Libraries

### Websites and Blogs
